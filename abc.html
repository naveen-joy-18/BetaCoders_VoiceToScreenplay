<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Voice-Driven Screenplay Creator</title>
  <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;500&family=Merriweather:wght@700&display=swap" rel="stylesheet">
  <style>
    body {
  font-family: 'Montserrat', sans-serif;
  color: #333;
  margin: 0;
  padding: 20px;
  position: relative; /* Required for positioning the pseudo-element */
}

body::before {
  content: ""; /* Necessary for the pseudo-element to display */
  position: absolute; /* Position it absolutely */
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: url('splash.png') no-repeat center center fixed; /* Background image */
  background-size: cover; /* Ensures the image covers the whole background */
  opacity: 0.35; /* Adjust opacity here */
  z-index: -1; /* Place it behind the content */
}

h1 {
  text-align: center;
  font-family: 'Merriweather', serif;
  color: #333;
  font-size: 3.5em;
  margin-bottom: 30px;
  font-weight: 700;
  letter-spacing: 2px;
  background: linear-gradient(to right, #9b59b6, #3498db, #e74c3c);
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  animation: sparkle 2s linear infinite;
}

@keyframes sparkle {
  0%, 100% { filter: brightness(1); }
  50% { filter: brightness(1.5); }
}

#controls {
  display: flex;
  justify-content: center;
  gap: 20px;
  margin-bottom: 20px;
}

button {
  padding: 12px 30px;
  font-size: 1.2em;
  cursor: pointer;
  border: none;
  border-radius: 8px;
  transition: background-color 0.3s ease, transform 0.2s ease, box-shadow 0.3s ease;
  box-shadow: 0 3px 8px rgba(0, 0, 0, 0.25);
  position: relative;
  overflow: hidden;
}

button::before {
  content: '';
  position: absolute;
  top: -50%;
  left: -50%;
  width: 200%;
  height: 200%;
  background: radial-gradient(circle, rgba(255, 255, 255, 0.5) 20%, transparent 20%);
  background-position: 0% 0%;
  background-size: 15px 15px;
  opacity: 0;
  transition: opacity 0.5s;
}

button:hover .stars {
  display:block;
  filter:drop-shadow(0 0 10px #fffdef);
}

@keyframes sparkle-hover {
  0%, 100% { background-position: 0% 0%; }
  50% { background-position: 100% 100%; }
}

#start {
  background-color: #34495e;
  color: #ffffff;
}

#start:hover {
  background-color: #3b5998;
  box-shadow: 0 4px 12px rgba(52, 73, 94, 0.8);
}

#stop {
  background-color: #c0392b;
  color: #ffffff;
}

#stop:hover {
  background-color: #e74c3c;
  box-shadow: 0 4px 12px rgba(192, 57, 43, 0.8);
}

#clear, #export, #saveEdit {
  background-color: #27ae60;
  color: #ffffff;
}

#clear:hover, #export:hover, #saveEdit:hover {
  background-color: #2ecc71;
  box-shadow: 0 4px 12px rgba(39, 174, 96, 0.8);
}

#screenplay {
  background-color: #ffffff;
  padding: 30px;
  margin: 0 auto;
  max-width: 850px;
  border: 1px solid #ddd;
  border-radius: 10px;
  min-height: 400px;
  box-shadow: 0 8px 20px rgba(0, 0, 0, 0.2);
  overflow-y: auto;
}

.scene {
  text-align: center;
  font-weight: bold;
  font-family: 'Merriweather', serif;
  margin: 25px 0;
  font-size: 1.8em;
  color: #8e44ad;
  text-shadow: 0 0 10px rgba(142, 68, 173, 0.8);
}

.location {
  font-weight: bold;
  color: #3498db;
  font-size: 1.4em;
  text-align: center;
  text-shadow: 0 0 5px rgba(52, 152, 219, 0.5);
}

.dialogue {
  margin-left: 40px;
  font-size: 1.2em;
  line-height: 1.6;
  font-family: 'Montserrat', sans-serif;
  color: #333;
}

.emotion {
  font-style: italic;
  color: #e67e22;
}

.camera-angle {
  font-weight: bold;
  color: #f39c12;
}

.location-left {
  font-weight: bold;
  color: #f1c40f;
  font-size: 1.4em;
  text-align: left;
  margin-left: 15px;
}

strong {
  font-weight: bold;
  color: #2c3e50;
}

#editArea {
  width: 100%;
  height: 140px;
  margin-top: 20px;
  font-size: 1.1em;
  padding: 15px;
  border-radius: 8px;
  border: 1px solid #ccc;
  background-color: #fafafa;
  color: #333;
  box-shadow: inset 0 3px 8px rgba(0, 0, 0, 0.2);
  resize: none;
}

#saveEdit {
  display: block;
  margin: 20px auto;
  padding: 12px 30px;
  font-size: 1.2em;
  background-color: #1abc9c;
  color: white;
  border: none;
  border-radius: 8px;
  cursor: pointer;
  transition: background-color 0.3s ease, box-shadow 0.3s ease;
}

#saveEdit:hover {
  background-color: #16a085;
  box-shadow: 0 4px 12px rgba(26, 188, 156, 0.8);
}

#status {
  text-align: center;
  font-size: 1.1em;
  color: #3498db;
  margin-top: 10px;
}

  </style>
</head>
<body>

<h1>Voice-Driven Screenplay Creator</h1>

<div id="controls">
  <button id="start">Start Narration</button>
  <button id="stop">Stop Narration</button>
  <button id="clear">Clear Screenplay</button>
  <button id="export">Export Screenplay</button>
</div>

<div id="status">Click "Start Narration" to begin</div>
<div id="screenplay"></div>

<textarea id="editArea" placeholder="Add custom Situation"></textarea>
<button id="saveEdit">Save Situation</button>

<script>
  const screenplay = document.getElementById('screenplay');
  const startButton = document.getElementById('start');
  const stopButton = document.getElementById('stop');
  const clearButton = document.getElementById('clear');
  const exportButton = document.getElementById('export');
  const editArea = document.getElementById('editArea');
  const saveEditButton = document.getElementById('saveEdit');
  const status = document.getElementById('status');

  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

  if (!SpeechRecognition) {
    alert('Your browser does not support Speech Recognition. Please use Google Chrome or another supported browser.');
  }

  const recognition = new SpeechRecognition();
  recognition.continuous = true;
  recognition.interimResults = true;
  recognition.lang = 'en-US';
  recognition.maxAlternatives = 1;

  let finalTranscript = '';

  startButton.addEventListener('click', () => {
    try {
      recognition.start();
      status.innerHTML = "Listening...";
      console.log("Voice recognition started.");
    } catch (error) {
      console.error("Error starting speech recognition:", error);
    }
  });

  stopButton.addEventListener('click', () => {
    recognition.stop();
    status.innerHTML = "Stopped listening.";
    console.log("Voice recognition stopped.");
  });

  clearButton.addEventListener('click', () => {
    screenplay.innerHTML = '';
    status.innerHTML = "Screenplay cleared.";
  });

  exportButton.addEventListener('click', () => {
    const blob = new Blob([screenplay.innerHTML], { type: 'text/plain' });
    const link = document.createElement('a');
    link.href = URL.createObjectURL(blob);
    link.download = 'screenplay.html';
    link.click();
    status.innerHTML = "Screenplay exported.";
  });

  recognition.onstart = function() {
    status.innerHTML = "Voice recognition is active.";
  };

  recognition.onerror = function(event) {
    console.error("Speech recognition error:", event.error);
    status.innerHTML = `Error: ${event.error}`;
  };

  recognition.onend = function() {
    console.log("Voice recognition ended.");
    status.innerHTML = "Voice recognition stopped.";
  };

  recognition.onresult = function(event) {
    let interimTranscript = '';

    for (let i = event.resultIndex; i < event.results.length; i++) {
      const transcript = event.results[i][0].transcript;
      const confidence = event.results[i][0].confidence;

      if (confidence < 0.5) {
        console.warn("Low confidence for result:", transcript);
        continue;
      }

      if (event.results[i].isFinal) {
        finalTranscript += transcript.trim() + ' ';
      } else {
        interimTranscript += transcript.trim() + ' ';
        status.innerHTML = "Processing: " + interimTranscript;
      }
    }

    if (finalTranscript) {
      processTranscript(finalTranscript.trim());
      finalTranscript = '';
    }
  };

  function processTranscript(transcript) {
    console.log("Processing transcript:", transcript);
    
    let formattedText = '';

    if (transcript.toLowerCase().includes("scene")) {
      let sceneNumber = transcript.match(/scene (\d+)/i);
      if (sceneNumber) {
        formattedText += `<p class="scene">Scene ${sceneNumber[1]}</p>`;
      }
    } else if (transcript.toLowerCase().includes("location is")) {
      let location = transcript.match(/location is (.+)/i);
      if (location) {
        formattedText += `<p class="location-left">Location: ${location[1].trim()}</p>`;
      }
    } else if (transcript.toLowerCase().includes("is the") || transcript.toLowerCase().includes("is a")) {
      let [character, role] = transcript.split(/is the|is a/);
      formattedText += `<p><strong>${character.trim()}:</strong> ${role.trim()}</p>`;
    } else if (transcript.toLowerCase().includes("said") || transcript.toLowerCase().includes("replied")
    || transcript.toLowerCase().includes("reply")) {
      let dialogue = transcript.replace(/.*?(said|replied|reply)\s+/, '').trim();
      let character = transcript.split(/(said|replied|reply)\s+/)[0].trim();

      // Identify emotion keywords
      let emotionMatch = dialogue.match(/\b(happily|sadly|angrily|excitedly|calmly)\b/i);
      let emotionText = emotionMatch ? `<span class="emotion">(${emotionMatch[0]})</span>` : '';

      // Remove emotion keyword from dialogue if detected
      if (emotionMatch) {
        dialogue = dialogue.replace(emotionMatch[0], '').trim();
      }

      formattedText += `<p class="dialogue"><strong>${character}:</strong> ${dialogue} ${emotionText}</p>`;
    } else if (transcript.toLowerCase().includes("wide short") || transcript.toLowerCase().includes("long short") || 
               transcript.toLowerCase().includes("close up short") || transcript.toLowerCase().includes("medium short")) {
      let cameraAngle = transcript.toLowerCase().includes("wide short") ? "[wide]" : 
                        transcript.toLowerCase().includes("long short") ? "[long]" : 
                        transcript.toLowerCase().includes("close up short") ? "[close-up]" : 
                        "[medium]";
      formattedText += `<p class="camera-angle">${cameraAngle}</p>`;
    } else {
      formattedText += `<p>${transcript}</p>`;
    }

    screenplay.innerHTML += formattedText;
    console.log("Updated screenplay:", formattedText);
  }

  saveEditButton.addEventListener('click', () => {
    const editedText = editArea.value.trim();
    if (editedText) {
      screenplay.innerHTML += `<p>${editedText}</p>`;
      editArea.value = '';
      status.innerHTML = "Add Custom Situation";
    } else {
      status.innerHTML = "Edit area is empty.";
    }
  });
</script>
</body>
</html>
